import pandas as pd
import numpy as np
import joblib
import tensorflow as tf
import xgboost as xgb
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import os
import warnings
warnings.filterwarnings('ignore')

# ==========================
# CONFIGURATION
# ==========================
# Get the backend directory (parent of test directory)
BACKEND_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
MODELS_DIR = os.path.join(BACKEND_DIR, "models")

# Chemins des modÃ¨les MLP
MLP_MODEL_PATH = os.path.join(MODELS_DIR, "mlp", "mlp_cicids2017_v2_optimized.keras")
MLP_SCALER_PATH = os.path.join(MODELS_DIR, "mlp", "scaler_mlp_optimized.pkl")
MLP_ENCODER_PATH = os.path.join(MODELS_DIR, "mlp", "label_encoder_mlp_optimized.pkl")

# Chemins des modÃ¨les XGBoost
XGB_MODEL_PATH = os.path.join(MODELS_DIR, "xgboost", "xgb_model_train_optimized2.json")
XGB_SCALER_PATH = os.path.join(MODELS_DIR, "xgboost", "scaler_xgb2.pkl")
XGB_ENCODER_PATH = os.path.join(MODELS_DIR, "xgboost", "encoder_xgb2.pkl")

# Chemin vers votre extrait de dataset
DATA_PATH = os.path.join(MODELS_DIR, "xgboost", "CIC-IDS-2017-V2.csv")

# ==========================
# 1) CHARGEMENT DES MODÃˆLES
# ==========================
print("="*70)
print("ðŸ”§ CHARGEMENT DES MODÃˆLES ET PRÃ‰PROCESSEURS")
print("="*70)

# MLP
print("\nðŸ“¥ Chargement du modÃ¨le MLP...")
mlp_model = tf.keras.models.load_model(MLP_MODEL_PATH, compile=False)
mlp_scaler = joblib.load(MLP_SCALER_PATH)
mlp_encoder = joblib.load(MLP_ENCODER_PATH)
print("âœ… MLP chargÃ© avec succÃ¨s")

# XGBoost
print("\nðŸ“¥ Chargement du modÃ¨le XGBoost...")
xgb_model = xgb.Booster()
xgb_model.load_model(XGB_MODEL_PATH)
xgb_scaler = joblib.load(XGB_SCALER_PATH)
xgb_encoder = joblib.load(XGB_ENCODER_PATH)
print("âœ… XGBoost chargÃ© avec succÃ¨s")

# Classes disponibles
classes_mlp = mlp_encoder.classes_
classes_xgb = xgb_encoder.classes_
print(f"\nðŸ“‹ Classes dÃ©tectables: {list(classes_mlp)}")

# ==========================
# 2) CHARGEMENT DES DONNÃ‰ES
# ==========================
print("\n" + "="*70)
print("ðŸ“‚ CHARGEMENT DES DONNÃ‰ES Ã€ ANALYSER")
print("="*70)

df = pd.read_csv(DATA_PATH)
print(f"âœ… Dataset chargÃ©: {df.shape[0]} lignes, {df.shape[1]} colonnes")

# Afficher les premiÃ¨res lignes
print("\nðŸ“Š AperÃ§u des donnÃ©es:")
print(df.head())

# VÃ©rifier si la colonne 'label' existe
has_labels = 'label' in df.columns

if has_labels:
    print("\nâœ… Labels rÃ©els trouvÃ©s dans le dataset")
    y_true = df['label']
    X = df.drop('label', axis=1)
else:
    print("\nâš ï¸  Pas de labels dans le dataset (dÃ©tection sur donnÃ©es non Ã©tiquetÃ©es)")
    X = df.copy()
    y_true = None

# Supprimer Timestamp si prÃ©sent
if 'Timestamp' in X.columns:
    X = X.drop('Timestamp', axis=1)

# Nettoyage
X.replace([np.inf, -np.inf], np.nan, inplace=True)
X.fillna(0, inplace=True)

print(f"\nâœ… DonnÃ©es prÃ©parÃ©es: {X.shape[0]} Ã©chantillons, {X.shape[1]} features")

# ==========================
# 3) FONCTION DE PRÃ‰DICTION
# ==========================
def predict_with_both_models(X_data):
    """Effectue les prÃ©dictions avec les deux modÃ¨les"""

    print("\n" + "="*70)
    print("ðŸ” DÃ‰TECTION DES ATTAQUES EN COURS...")
    print("="*70)

    # PrÃ©diction MLP
    print("\nðŸ§  PrÃ©diction avec MLP...")
    X_scaled_mlp = mlp_scaler.transform(X_data)
    mlp_proba = mlp_model.predict(X_scaled_mlp, batch_size=256, verbose=0)
    mlp_pred_encoded = np.argmax(mlp_proba, axis=1)
    mlp_pred = mlp_encoder.inverse_transform(mlp_pred_encoded)
    mlp_confidence = np.max(mlp_proba, axis=1)
    print("âœ… PrÃ©dictions MLP terminÃ©es")

    # PrÃ©diction XGBoost
    print("\nðŸŒ³ PrÃ©diction avec XGBoost...")
    X_scaled_xgb = xgb_scaler.transform(X_data)
    dmatrix = xgb.DMatrix(X_scaled_xgb)
    xgb_proba = xgb_model.predict(dmatrix)
    xgb_pred_encoded = np.argmax(xgb_proba, axis=1)
    xgb_pred = xgb_encoder.inverse_transform(xgb_pred_encoded)
    xgb_confidence = np.max(xgb_proba, axis=1)
    print("âœ… PrÃ©dictions XGBoost terminÃ©es")

    return {
        'mlp_pred': mlp_pred,
        'mlp_confidence': mlp_confidence,
        'mlp_proba': mlp_proba,
        'xgb_pred': xgb_pred,
        'xgb_confidence': xgb_confidence,
        'xgb_proba': xgb_proba
    }

# ==========================
# 4) EFFECTUER LES PRÃ‰DICTIONS
# ==========================
predictions = predict_with_both_models(X)

# ==========================
# 5) CRÃ‰ER UN DATAFRAME DE RÃ‰SULTATS
# ==========================
print("\n" + "="*70)
print("ðŸ“Š CRÃ‰ATION DU RAPPORT DE DÃ‰TECTION")
print("="*70)

results_df = pd.DataFrame({
    'Index': range(len(X)),
    'MLP_Prediction': predictions['mlp_pred'],
    'MLP_Confidence': predictions['mlp_confidence'],
    'XGBoost_Prediction': predictions['xgb_pred'],
    'XGBoost_Confidence': predictions['xgb_confidence'],
    'Accord_Modeles': predictions['mlp_pred'] == predictions['xgb_pred']
})

# Ajouter les labels rÃ©els si disponibles
if has_labels:
    results_df.insert(1, 'Label_Reel', y_true.values)
    results_df['MLP_Correct'] = results_df['MLP_Prediction'] == results_df['Label_Reel']
    results_df['XGBoost_Correct'] = results_df['XGBoost_Prediction'] == results_df['Label_Reel']

# CatÃ©goriser les attaques
results_df['MLP_Est_Attaque'] = results_df['MLP_Prediction'] != 'BENIGN'
results_df['XGBoost_Est_Attaque'] = results_df['XGBoost_Prediction'] != 'BENIGN'

print("\nâœ… Rapport crÃ©Ã© avec succÃ¨s")

# ==========================
# 6) AFFICHAGE DES RÃ‰SULTATS
# ==========================
print("\n" + "="*70)
print("ðŸŽ¯ RÃ‰SULTATS DE LA DÃ‰TECTION")
print("="*70)

# Statistiques globales
total_samples = len(results_df)
mlp_attacks = results_df['MLP_Est_Attaque'].sum()
xgb_attacks = results_df['XGBoost_Est_Attaque'].sum()
both_attacks = (results_df['MLP_Est_Attaque'] & results_df['XGBoost_Est_Attaque']).sum()
accord = results_df['Accord_Modeles'].sum()

print(f"\nðŸ“Š STATISTIQUES GLOBALES:")
print(f"   â€¢ Total d'Ã©chantillons analysÃ©s: {total_samples}")
print(f"   â€¢ Attaques dÃ©tectÃ©es par MLP: {mlp_attacks} ({mlp_attacks/total_samples*100:.2f}%)")
print(f"   â€¢ Attaques dÃ©tectÃ©es par XGBoost: {xgb_attacks} ({xgb_attacks/total_samples*100:.2f}%)")
print(f"   â€¢ Attaques dÃ©tectÃ©es par les DEUX: {both_attacks} ({both_attacks/total_samples*100:.2f}%)")
print(f"   â€¢ Accord entre les modÃ¨les: {accord} ({accord/total_samples*100:.2f}%)")

# Distribution des prÃ©dictions
print(f"\nðŸ“‹ DISTRIBUTION DES PRÃ‰DICTIONS MLP:")
mlp_counts = Counter(predictions['mlp_pred'])
for attack_type, count in mlp_counts.most_common():
    print(f"   â€¢ {attack_type}: {count} ({count/total_samples*100:.2f}%)")

print(f"\nðŸ“‹ DISTRIBUTION DES PRÃ‰DICTIONS XGBOOST:")
xgb_counts = Counter(predictions['xgb_pred'])
for attack_type, count in xgb_counts.most_common():
    print(f"   â€¢ {attack_type}: {count} ({count/total_samples*100:.2f}%)")

# Si labels rÃ©els disponibles
if has_labels:
    mlp_accuracy = results_df['MLP_Correct'].sum() / total_samples * 100
    xgb_accuracy = results_df['XGBoost_Correct'].sum() / total_samples * 100
    print(f"\nðŸŽ¯ PRÃ‰CISION SUR CET EXTRAIT:")
    print(f"   â€¢ MLP: {mlp_accuracy:.2f}%")
    print(f"   â€¢ XGBoost: {xgb_accuracy:.2f}%")

# ==========================
# 7) AFFICHER LES DÃ‰SACCORDS
# ==========================
print("\n" + "="*70)
print("âš ï¸  DÃ‰SACCORDS ENTRE LES MODÃˆLES")
print("="*70)

disagreements = results_df[~results_df['Accord_Modeles']]
if len(disagreements) > 0:
    print(f"\nâŒ {len(disagreements)} dÃ©saccords trouvÃ©s ({len(disagreements)/total_samples*100:.2f}%)")
    print("\nPremiers exemples de dÃ©saccords:")
    cols_to_show = ['Index', 'MLP_Prediction', 'MLP_Confidence',
                    'XGBoost_Prediction', 'XGBoost_Confidence']
    if has_labels:
        cols_to_show.insert(1, 'Label_Reel')
    print(disagreements[cols_to_show].head(10).to_string(index=False))
else:
    print("\nâœ… Accord parfait entre les deux modÃ¨les!")

# ==========================
# 8) EXEMPLES D'ATTAQUES DÃ‰TECTÃ‰ES
# ==========================
print("\n" + "="*70)
print("ðŸš¨ EXEMPLES D'ATTAQUES DÃ‰TECTÃ‰ES")
print("="*70)

attacks_detected = results_df[results_df['MLP_Est_Attaque'] | results_df['XGBoost_Est_Attaque']]
if len(attacks_detected) > 0:
    print(f"\nâš ï¸  {len(attacks_detected)} attaques dÃ©tectÃ©es au total")
    print("\nPremiers exemples:")
    cols_to_show = ['Index', 'MLP_Prediction', 'MLP_Confidence',
                    'XGBoost_Prediction', 'XGBoost_Confidence', 'Accord_Modeles']
    if has_labels:
        cols_to_show.insert(1, 'Label_Reel')
    print(attacks_detected[cols_to_show].head(15).to_string(index=False))
else:
    print("\nâœ… Aucune attaque dÃ©tectÃ©e - Tout le trafic semble bÃ©nin")

# ==========================
# 9) VISUALISATIONS
# ==========================
print("\n" + "="*70)
print("ðŸ“Š GÃ‰NÃ‰RATION DES VISUALISATIONS")
print("="*70)

# Graphique 1: Distribution des prÃ©dictions
fig, axes = plt.subplots(1, 2, figsize=(16, 6))
fig.suptitle('Distribution des PrÃ©dictions par ModÃ¨le', fontsize=16, fontweight='bold')

# MLP
mlp_df = pd.DataFrame.from_dict(mlp_counts, orient='index', columns=['Count'])
mlp_df = mlp_df.sort_values('Count', ascending=False)
axes[0].bar(range(len(mlp_df)), mlp_df['Count'], color='#3498db', alpha=0.8, edgecolor='black')
axes[0].set_xticks(range(len(mlp_df)))
axes[0].set_xticklabels(mlp_df.index, rotation=45, ha='right')
axes[0].set_title('MLP', fontweight='bold')
axes[0].set_ylabel('Nombre de dÃ©tections')
axes[0].grid(axis='y', alpha=0.3)

# XGBoost
xgb_df = pd.DataFrame.from_dict(xgb_counts, orient='index', columns=['Count'])
xgb_df = xgb_df.sort_values('Count', ascending=False)
axes[1].bar(range(len(xgb_df)), xgb_df['Count'], color='#e74c3c', alpha=0.8, edgecolor='black')
axes[1].set_xticks(range(len(xgb_df)))
axes[1].set_xticklabels(xgb_df.index, rotation=45, ha='right')
axes[1].set_title('XGBoost', fontweight='bold')
axes[1].set_ylabel('Nombre de dÃ©tections')
axes[1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('predictions_distribution.png', dpi=300, bbox_inches='tight')
print("âœ… Graphique 'predictions_distribution.png' crÃ©Ã©")
plt.show()

# Graphique 2: Comparaison Attaques vs BÃ©nin
fig, ax = plt.subplots(figsize=(10, 6))
categories = ['BÃ©nin', 'Attaque']
mlp_data = [total_samples - mlp_attacks, mlp_attacks]
xgb_data = [total_samples - xgb_attacks, xgb_attacks]

x = np.arange(len(categories))
width = 0.35

bars1 = ax.bar(x - width/2, mlp_data, width, label='MLP', color='#3498db', alpha=0.8, edgecolor='black')
bars2 = ax.bar(x + width/2, xgb_data, width, label='XGBoost', color='#e74c3c', alpha=0.8, edgecolor='black')

ax.set_xlabel('Type de trafic', fontweight='bold')
ax.set_ylabel('Nombre de dÃ©tections', fontweight='bold')
ax.set_title('Comparaison: Trafic BÃ©nin vs Attaques', fontweight='bold', fontsize=14)
ax.set_xticks(x)
ax.set_xticklabels(categories)
ax.legend()
ax.grid(axis='y', alpha=0.3)

# Ajouter les valeurs sur les barres
for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{int(height)}',
               ha='center', va='bottom', fontweight='bold')

plt.tight_layout()
plt.savefig('benign_vs_attacks.png', dpi=300, bbox_inches='tight')
print("âœ… Graphique 'benign_vs_attacks.png' crÃ©Ã©")
plt.show()

# Graphique 3: Accord entre modÃ¨les
fig, ax = plt.subplots(figsize=(10, 6))
accord_data = [accord, total_samples - accord]
colors = ['#2ecc71', '#e67e22']
explode = (0.1, 0)

ax.pie(accord_data, explode=explode, labels=['Accord', 'DÃ©saccord'],
       colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)
ax.set_title('Accord entre MLP et XGBoost', fontweight='bold', fontsize=14)

plt.tight_layout()
plt.savefig('model_agreement.png', dpi=300, bbox_inches='tight')
print("âœ… Graphique 'model_agreement.png' crÃ©Ã©")
plt.show()

# Graphique 4: Distribution des niveaux de confiance
fig, axes = plt.subplots(1, 2, figsize=(16, 6))
fig.suptitle('Distribution des Niveaux de Confiance', fontsize=16, fontweight='bold')

axes[0].hist(predictions['mlp_confidence'], bins=50, color='#3498db', alpha=0.7, edgecolor='black')
axes[0].axvline(predictions['mlp_confidence'].mean(), color='red', linestyle='--',
                linewidth=2, label=f'Moyenne: {predictions["mlp_confidence"].mean():.3f}')
axes[0].set_xlabel('Confiance')
axes[0].set_ylabel('FrÃ©quence')
axes[0].set_title('MLP', fontweight='bold')
axes[0].legend()
axes[0].grid(alpha=0.3)

axes[1].hist(predictions['xgb_confidence'], bins=50, color='#e74c3c', alpha=0.7, edgecolor='black')
axes[1].axvline(predictions['xgb_confidence'].mean(), color='red', linestyle='--',
                linewidth=2, label=f'Moyenne: {predictions["xgb_confidence"].mean():.3f}')
axes[1].set_xlabel('Confiance')
axes[1].set_ylabel('FrÃ©quence')
axes[1].set_title('XGBoost', fontweight='bold')
axes[1].legend()
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('confidence_distribution.png', dpi=300, bbox_inches='tight')
print("âœ… Graphique 'confidence_distribution.png' crÃ©Ã©")
plt.show()

# ==========================
# 10) SAUVEGARDE DES RÃ‰SULTATS
# ==========================
print("\n" + "="*70)
print("ðŸ’¾ SAUVEGARDE DES RÃ‰SULTATS")
print("="*70)

# Sauvegarder le DataFrame complet
output_filename = f"detection_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
results_df.to_csv(output_filename, index=False)
print(f"âœ… RÃ©sultats sauvegardÃ©s dans '{output_filename}'")

# Sauvegarder uniquement les attaques dÃ©tectÃ©es
if len(attacks_detected) > 0:
    attacks_filename = f"attacks_detected_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    attacks_detected.to_csv(attacks_filename, index=False)
    print(f"âœ… Attaques dÃ©tectÃ©es sauvegardÃ©es dans '{attacks_filename}'")

# Sauvegarder les dÃ©saccords
if len(disagreements) > 0:
    disagreements_filename = f"model_disagreements_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    disagreements.to_csv(disagreements_filename, index=False)
    print(f"âœ… DÃ©saccords sauvegardÃ©s dans '{disagreements_filename}'")

# ==========================
# 11) RÃ‰SUMÃ‰ FINAL
# ==========================
print("\n" + "="*70)
print("âœ… DÃ‰TECTION TERMINÃ‰E - RÃ‰SUMÃ‰")
print("="*70)

print(f"\nðŸ“Š RÃ‰SULTATS PRINCIPAUX:")
print(f"   â€¢ {total_samples} Ã©chantillons analysÃ©s")
print(f"   â€¢ {mlp_attacks} attaques dÃ©tectÃ©es par MLP")
print(f"   â€¢ {xgb_attacks} attaques dÃ©tectÃ©es par XGBoost")
print(f"   â€¢ {both_attacks} attaques confirmÃ©es par les deux modÃ¨les")
print(f"   â€¢ {accord/total_samples*100:.2f}% d'accord entre les modÃ¨les")

if has_labels:
    print(f"\nðŸŽ¯ PRÃ‰CISION:")
    print(f"   â€¢ MLP: {mlp_accuracy:.2f}%")
    print(f"   â€¢ XGBoost: {xgb_accuracy:.2f}%")
    better_model = "MLP" if mlp_accuracy > xgb_accuracy else "XGBoost" if xgb_accuracy > mlp_accuracy else "Ã‰galitÃ©"
    print(f"   â€¢ Meilleur modÃ¨le: {better_model}")

print(f"\nðŸ“ FICHIERS GÃ‰NÃ‰RÃ‰S:")
print(f"   â€¢ {output_filename}")
if len(attacks_detected) > 0:
    print(f"   â€¢ {attacks_filename}")
if len(disagreements) > 0:
    print(f"   â€¢ {disagreements_filename}")
print(f"   â€¢ predictions_distribution.png")
print(f"   â€¢ benign_vs_attacks.png")
print(f"   â€¢ model_agreement.png")
print(f"   â€¢ confidence_distribution.png")

print("\n" + "="*70)
print("ðŸŽ‰ ANALYSE COMPLÃˆTE TERMINÃ‰E !")
print("="*70)